{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e01fe6e4",
   "metadata": {},
   "source": [
    "## Pipeline in Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615434d",
   "metadata": {},
   "source": [
    "![Spacy Loaded Pipeline](spacy_loaded_pipeline.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc6829e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17926ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x164489b50>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x164489d30>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x16445f140>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x164777a10>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1647609d0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x16445f1b0>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm') # loading a spacy Model; it is a pre trained pipeline, check above image\n",
    "\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce63cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captain | PROPN | Captain\n",
      "America | PROPN | America\n",
      "are | AUX | be\n",
      "100 | NUM | 100\n",
      "$ | NUM | $\n",
      "of | ADP | of\n",
      "Samosa | PROPN | Samosa\n",
      ". | PUNCT | .\n",
      "Then | ADV | then\n",
      "he | PRON | he\n",
      "said | VERB | say\n",
      "I | PRON | I\n",
      "want | VERB | want\n",
      "to | PART | to\n",
      "eat | VERB | eat\n",
      "6 | NUM | 6\n",
      "plates | NOUN | plate\n",
      "of | ADP | of\n",
      "Pani | PROPN | Pani\n",
      "Puri | PROPN | Puri\n",
      "at | ADP | at\n",
      "Sai | PROPN | Sai\n",
      "GupChup | PROPN | GupChup\n",
      ". | PUNCT | .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Captain America are 100$ of Samosa. Then he said I want to eat 6 plates of Pani Puri at Sai GupChup.\")\n",
    "\n",
    "# pos - part of speech, lemma\n",
    "for token in doc:\n",
    "    print(token, token.pos_, token.lemma_, sep=\" | \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b6fbe",
   "metadata": {},
   "source": [
    "### Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29adfff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple || ORG || Companies, agencies, institutions, etc.\n",
      "$45 billion || MONEY || Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Tesla Inc is going to acquire twitter for $45 billion')\n",
    "\n",
    "doc = nlp('Apple is going to acquire twitter for $45 billion')\n",
    "\n",
    "# doc = nlp(\"Apple is a very nutritious fruit.\")\n",
    "\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_, spacy.explain(ent.label_), sep=\" || \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9733cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVIEW: this code is not working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "985bc320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Apple\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n is going to acquire twitter for \\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    $45 billion\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\\n</mark>\\n</div>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27eab29",
   "metadata": {},
   "source": [
    "## Adding components to a blank pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d14f261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# with full components in pipeline\n",
    "source_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# with only tokenizer in pipeline\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3296d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(\"ner\", source=source_nlp) # is ner a reserved keyword? \n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04a10c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple || ORG || Companies, agencies, institutions, etc.\n",
      "$45 billion || MONEY || Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Apple is going to acquire twitter for $45 billion')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_, spacy.explain(ent.label_), sep=\" || \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
