{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d517148b",
   "metadata": {},
   "source": [
    "## NLTK vs Spacy\n",
    "Both are python libraries to handle NLP tasks\n",
    "1. spacy is object oriented lib\n",
    "2. nltk is string processing lib\n",
    "3. spacy gives most efficient algo while nltk has option to choose from multiple algos (automatic vs mannual transmission kind of comparision)\n",
    "4. nltk is good for research and more control, while spacy is good for getting the job done quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "173cd972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d5e7dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi I am feeling like eating Samosa and Vada Pao.\n",
      "Indian street food is just amazing.\n",
      "What is our Dr. going to say\n",
      "Word :0 Hi\n",
      "Word :1 I\n",
      "Word :2 am\n",
      "Word :3 feeling\n",
      "Word :4 like\n",
      "Word :5 eating\n",
      "Word :6 Samosa\n",
      "Word :7 and\n",
      "Word :8 Vada\n",
      "Word :9 Pao\n",
      "Word :10 .\n",
      "Word :0 Indian\n",
      "Word :1 street\n",
      "Word :2 food\n",
      "Word :3 is\n",
      "Word :4 just\n",
      "Word :5 amazing\n",
      "Word :6 .\n",
      "Word :0 What\n",
      "Word :1 is\n",
      "Word :2 our\n",
      "Word :3 Dr.\n",
      "Word :4 going\n",
      "Word :5 to\n",
      "Word :6 say\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = 'Hi I am feeling like eating Samosa and Vada Pao. Indian street food is just amazing. What is our Dr. going to say'\n",
    "\n",
    "doc = nlp('Hi I am feeling like eating Samosa and Vada Pao. Indian street food is just amazing. What is our Dr. going to say')\n",
    "\n",
    "\n",
    "# print sentences\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)\n",
    "    \n",
    "# - this is quite amazing, as it is not just like find a dot and make it a sentence.\n",
    "# it is smart enough to print actual sentences\n",
    "\n",
    "# print each word\n",
    "for sentence in doc.sents:\n",
    "    for i, word in enumerate(sentence):\n",
    "        print(f'Word :{i}', word)\n",
    "        \n",
    "# NOTE: see our Dr. with a dot is treated! Smart!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6723a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc9a0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shashankrajak/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512379eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokenize(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
